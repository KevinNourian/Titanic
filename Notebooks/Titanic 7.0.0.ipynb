{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25aaf1b5",
   "metadata": {},
   "source": [
    "# <center> **Titanic**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c8da2",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73e35264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from 'c:\\\\Users\\\\Dell\\\\Documents\\\\AI\\\\Titanic\\\\Notebooks\\\\functions.py'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "importlib.reload(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169bb5d",
   "metadata": {},
   "source": [
    "# **Data Overview and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e358ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    r\"C:\\Users\\Dell\\Documents\\AI\\Titanic\\Data\\data.csv\",\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "train = pd.read_csv(\n",
    "    r\"C:\\Users\\Dell\\Documents\\AI\\Titanic\\Data\\Data\\train.csv\",\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "test = pd.read_csv(\n",
    "    r\"C:\\Users\\Dell\\Documents\\AI\\Titanic\\Data\\Data\\test.csv\",\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "\n",
    "random_state = 101\n",
    "target = 'Transported'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c97564",
   "metadata": {},
   "source": [
    "# **Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3663d",
   "metadata": {},
   "source": [
    "## **Split Data Back to Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a099298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=data[data['PassengerId'].isin(train['PassengerId'].values)].copy()\n",
    "test=data[data['PassengerId'].isin(test['PassengerId'].values)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d267b4e",
   "metadata": {},
   "source": [
    "# **Drop Unneeded Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8f18a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['PassengerId', 'Group', 'CabinNumber'], axis=1, inplace=True)\n",
    "test.drop(['PassengerId', 'Group', 'CabinNumber'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28f9b8",
   "metadata": {},
   "source": [
    "# **Log Transform**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe888dfb",
   "metadata": {},
   "source": [
    "The logarithm transform is used to decrease skew in distributions, especially with large outliers. It can make it easier for algorithms to 'learn' the correct relationships. We will apply it to the expenditure features as these are heavily skewed by outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eaa7d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_transform = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'TotalSpent']  # Replace with your actual column names\n",
    "\n",
    "for col in columns_to_transform:\n",
    "    train = functions.log_transform(train, col)\n",
    "    test = functions.log_transform(test, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e753e26",
   "metadata": {},
   "source": [
    "## **Column Separation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68029f11",
   "metadata": {},
   "source": [
    "### **Numerical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a8f60d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [cname for cname in train.columns if train[cname].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8494704",
   "metadata": {},
   "source": [
    "### **Categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "56bc4455",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [cname for cname in train.columns if train[cname].dtype in [\"object\", \"bool\"]]\n",
    "categorical_cols.remove(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccdb9b",
   "metadata": {},
   "source": [
    "## **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c3c1ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(target, axis=1)\n",
    "y = train[target]\n",
    "y = y.astype(bool)\n",
    "\n",
    "\n",
    "X, y = shuffle(X, y, random_state=random_state)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80391a5d",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7416d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor  = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "\n",
    "lg_model = LogisticRegression(class_weight='balanced', max_iter=5000)\n",
    "lg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lg', lg_model)\n",
    "])\n",
    "\n",
    "pipelines = {\n",
    "    \"Logistic Regression\": lg_pipeline\n",
    "}\n",
    "\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    scores = cross_val_score(pipeline, X, y, cv=10)\n",
    "    print(f\"{name}: {scores.mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
