{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25aaf1b5",
   "metadata": {},
   "source": [
    "# <center> **Titanic**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c8da2",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e35264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-arlington",
   "metadata": {},
   "source": [
    "# **Display Parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-logging",
   "metadata": {},
   "source": [
    "## **Display Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 300000\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-officer",
   "metadata": {},
   "source": [
    "## **Colors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_1 = \"bisque\"\n",
    "color_2 = \"crimson\"\n",
    "color_3 = \"orangered\"\n",
    "color_4 = \"lightcoral\"\n",
    "color_5 = \"royalblue\"\n",
    "color_6 = \"pink\"\n",
    "color_7 = \"indianred\"\n",
    "color_8 = \"slategrey\"\n",
    "color_9 = \"salmon\"\n",
    "color_10 = \"beige\"\n",
    "color_11 = \"coral\"\n",
    "color_13 = \"grey\"\n",
    "color_14 = \"tan\"\n",
    "color_15 = \"wheat\"\n",
    "color_16 = \"tomato\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-stupid",
   "metadata": {},
   "source": [
    "## **Figure Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 20\n",
    "\n",
    "params = {\n",
    "    \"font.family\": \"Times New Roman\",\n",
    "    \"font.size\": size,\n",
    "    \"axes.labelsize\": size,\n",
    "    \"xtick.labelsize\": size * 0.75,\n",
    "    \"ytick.labelsize\": size * 0.75,\n",
    "    \"figure.titlesize\": size * 1.5,\n",
    "    \"axes.titlesize\": size * 1.5,\n",
    "    \"axes.titlepad\": size,\n",
    "    \"axes.labelpad\": size - 10,\n",
    "    \"lines.linewidth\": 2,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.spines.left\": False,\n",
    "    \"axes.spines.bottom\": False,\n",
    "    \"legend.fontsize\": size,\n",
    "    \"figure.figsize\": (10, 6),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169bb5d",
   "metadata": {},
   "source": [
    "# **Data Overview and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    r\"C:\\Users\\Dell\\Documents\\Stroke\\Data\\stroke.csv\",\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "random_state = 101\n",
    "target = 'Stroke'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57db4d52",
   "metadata": {},
   "source": [
    "## **Number of Rows and Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566cb3e",
   "metadata": {},
   "source": [
    "## **Dataset Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716c0ae",
   "metadata": {},
   "source": [
    "1. **Gender:** Gender of the patient (Male or Female).\n",
    "2. **Age:** Age of the patient (float).\n",
    "3. **Hypertension:** 0 for no hypertension diagnosis. 1 for hypertion diagnosis.\n",
    "4. **Heart Disease:** 0 for no diagnosis for heart disease. 1 for heart disease diagnosis.\n",
    "5. **Ever Married:** Yes: The patient has been married or is married. No: The patient has never been married.\n",
    "6. **Work:** Type of work: Private, Self-Employed, Government, Never Worked, Children (The patient is a child)\n",
    "7. **Residence:** Two values: Rural, Urban\n",
    "8. **AVG Glucose:** Average glucose level of the patient.\n",
    "9. **BMI:** Body Mass Index of the patient.\n",
    "10. **Smoking:**: Does the patient smoke now or before. Values: Unknown, Formerly Smoked, Never Smokes, Smokes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb434f64",
   "metadata": {},
   "source": [
    "## **Missing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847dc668",
   "metadata": {},
   "source": [
    "## **Duplicate Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e7b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.duplicated(keep=False)].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5365d0b",
   "metadata": {},
   "source": [
    "# **Descriptive Information**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604580f",
   "metadata": {},
   "source": [
    "### **Data Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e164b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0856130a",
   "metadata": {},
   "source": [
    "### **Descriptive Information for Numerical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f329f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Stroke']).describe(include=\"number\").applymap(\"{:,.2f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfad5a1",
   "metadata": {},
   "source": [
    "### **Descriptive Information for Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956058f8",
   "metadata": {},
   "source": [
    "### **Outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562673f2",
   "metadata": {},
   "source": [
    "An outlier is an observation that is unlike the other observations.\n",
    "\n",
    "I used the **Interquartile Range (IQR)** method to identify outliers. The IQR is calculated as the difference between the 75th and the 25th percentiles of the data and defines the box in a box and whisker plot. I chose to show the outliers numerically instead of graphically. I saw more value in this type of presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d4c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = data.select_dtypes(include=['number'])\n",
    "\n",
    "Q1 = numeric_data.quantile(0.25)\n",
    "Q3 = numeric_data.quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = (numeric_data < (Q1 - 1.5 * IQR)) | (numeric_data > (Q3 + 1.5 * IQR))\n",
    "\n",
    "outlier_counts = outliers.sum()\n",
    "print (outlier_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e9746",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * There are over 5,000 records in this dataset.\n",
    "> * Of the 10 features, 7 are categorical, and 3 are numerical.  \n",
    "> * The target is the column 'Stroke', with values 0 or 1. \n",
    "> * There are 201 null values in the BMI column. The other 9 columns have no null values.\n",
    "> * Using the IQR method to identify outliers, I identified outliers in every numerical feature, except Age.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495bf8d",
   "metadata": {},
   "source": [
    "# **Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59faebea",
   "metadata": {},
   "source": [
    "Below are the functions that I utilized in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e4cbd",
   "metadata": {},
   "source": [
    "## **Side-by-Side Bar Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def side_by_side_barplot(data_1, data_2, title_1, title_2, labels, feature, y, palette):\n",
    "\n",
    "    '''\n",
    "    Creates a side-by-side bar plot comparing two datasets.\n",
    "    '''\n",
    "\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    sns.barplot(data=data_1, x=feature, y=y, ax=ax1, palette=palette)\n",
    "    sns.barplot(data=data_2, x=feature, y=y, ax=ax2, palette=palette)\n",
    "\n",
    "    ax1.set_xlabel(feature)\n",
    "    ax1.set_ylabel(y)\n",
    "    ax2.set_xlabel(feature)\n",
    "    ax2.set_ylabel(y)\n",
    "\n",
    "    total_count1 = data_1[y].sum()\n",
    "    for container in ax1.containers:\n",
    "        labels = [f'{(v.get_height() / total_count1 * 100):.1f}%' for v in container]\n",
    "        ax1.bar_label(container, labels=labels, size=size)\n",
    "\n",
    "    total_count2 = data_2[y].sum()\n",
    "    for container in ax2.containers:\n",
    "        labels = [f'{(v.get_height() / total_count2 * 100):.1f}%' for v in container]\n",
    "        ax2.bar_label(container, labels=labels, size=size)\n",
    "\n",
    "    ax1.set_title(title_1)\n",
    "    ax2.set_title(title_2)\n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b920f26d",
   "metadata": {},
   "source": [
    "## **Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distributions(data, feature, target, value):\n",
    "\n",
    "    '''\n",
    "    Creates a distribution of counts for a specific feature within a subset of data.\n",
    "    '''\n",
    "    \n",
    "    df = data[data[target] == value]\n",
    "    distribution= df.groupby(feature).size().reset_index()\n",
    "    distribution.columns = [feature, 'Count']\n",
    "\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b724cf8",
   "metadata": {},
   "source": [
    "## **Create Bins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bins(df, feature, new_feature, bins, labels):\n",
    "\n",
    "    '''\n",
    "    Creates bins for continuous features.\n",
    "    '''\n",
    "\n",
    "    df[new_feature] = pd.cut(df[feature], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c365a59",
   "metadata": {},
   "source": [
    "## **Count Bins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bins(df, new_feature):\n",
    "\n",
    "    '''\n",
    "    Counts the number of observations in each bin.\n",
    "    '''\n",
    "    \n",
    "    group_counts = df[new_feature].value_counts().sort_index()\n",
    "    group_counts_df = group_counts.reset_index()\n",
    "    group_counts_df.columns = [new_feature, 'Count']\n",
    "\n",
    "    return group_counts_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b17765",
   "metadata": {},
   "source": [
    "## **Heat Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(data, title):\n",
    "\n",
    "    '''\n",
    "    Creates a Seaborn heatmap.\n",
    "    '''\n",
    "\n",
    "    plt.rcParams.update(params)\n",
    "    corr = data.corr()\n",
    "\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(25, 25))\n",
    "\n",
    "    cmap = sns.diverging_palette(230, 10, as_cmap=True)\n",
    "    heatmap = sns.heatmap(\n",
    "        corr,\n",
    "        mask=mask,\n",
    "        vmax=1,\n",
    "        vmin=-1,\n",
    "        center=0,\n",
    "        square=True,\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"shrink\": 0.5},\n",
    "        annot=True,\n",
    "        cmap=plt.cm.Reds,\n",
    "    )\n",
    "\n",
    "    heatmap.set_title(\n",
    "        title,\n",
    "        fontdict={\"fontsize\": size},\n",
    "        pad=12,\n",
    "    )\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8702f85",
   "metadata": {},
   "source": [
    "## **Mutual Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c10f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot_mi_scores(features, mi_scores):\n",
    "    \n",
    "    '''\n",
    "    Creates a plot of mutual information scores.\n",
    "    '''\n",
    "\n",
    "    plt.rcParams.update({'figure.autolayout': True}) \n",
    "\n",
    "    scores = pd.Series(mi_scores, name=\"MI Scores\", index=features.columns)\n",
    "    scores = scores.sort_values(ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    scores.plot(kind=\"line\", marker='o')\n",
    "\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"MI Score\")\n",
    "\n",
    "    plt.xticks(ticks=range(len(scores)), labels=scores.index, rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ce9bbe",
   "metadata": {},
   "source": [
    "## **Two-Sample T-Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03146739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sample_t_test(sample1, sample2, variance):\n",
    "    \n",
    "    \"\"\"\n",
    "    Determines if the means of two samples are significanlty different.\n",
    "    \"\"\"\n",
    "    \n",
    "    if variance is False:\n",
    "        print(\"The variance of the samples are different.\")\n",
    "    else:\n",
    "        print(\"The variance of the samples are the same.\")\n",
    "\n",
    "    result = stats.ttest_ind(sample1, sample2, equal_var=variance)\n",
    "\n",
    "    p_value = result.pvalue\n",
    "    \n",
    "    p_value = \"{:.20f}\".format(p_value)\n",
    "    print(\"The p-value is: \", p_value)\n",
    "\n",
    "    \n",
    "    if result.pvalue < 0.05:\n",
    "        print(\"Null hypothesis is rejected.\")\n",
    "    else:\n",
    "        print(\"Failed to reject the null hypothesis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce68a8",
   "metadata": {},
   "source": [
    "# **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ee13b",
   "metadata": {},
   "source": [
    "## **Gender**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb7fcbc",
   "metadata": {},
   "source": [
    "In this section, I show the distribution of genders among patients who suffered a stroke and those who did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Gender'\n",
    "target = 'Stroke'\n",
    "data = data.copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wi_stroke_gender = create_distributions(data, feature, target, value = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stroke_gender = create_distributions(data, feature, target, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Male', 'Female']\n",
    "palette = [color_1, color_2]\n",
    "y = 'Count'\n",
    "\n",
    "data_1 = wi_stroke_gender\n",
    "data_2 = no_stroke_gender\n",
    "title_1 = 'Gender Distribution of Stroke Patients'\n",
    "title_2 = 'Gender Distribution of Non-Stroke Patients'\n",
    "\n",
    "side_by_side_barplot(data_1, data_2, title_1, title_2, labels, feature, y, palette);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eff419",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * Gender distribution is almost the same in patients who suffered a stroke and those who did not. \n",
    "> * From this data we can suggest that the medical establishments should look at both genders equally when assessing this ailment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4eb2c8",
   "metadata": {},
   "source": [
    "## **Hypertension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Hypertension'\n",
    "target = 'Stroke'\n",
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f217f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wi_stroke_hypertension = create_distributions(data, feature, target, value = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stroke_hypertension = create_distributions(data, feature, target, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7962715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1]\n",
    "palette = [color_3, color_4]\n",
    "y = 'Count'\n",
    "\n",
    "data_1 = wi_stroke_hypertension.copy() \n",
    "data_2 = no_stroke_hypertension.copy()\n",
    "data_1 ['Hypertension'] = data_1['Hypertension'].replace({0: 'No', 1: 'Yes'})\n",
    "data_2 ['Hypertension'] = data_2['Hypertension'].replace({0: 'No', 1: 'Yes'})\n",
    "title_1 = 'Hypertension Among Stroke Patients'\n",
    "title_2 = 'Hypertension Among Non-Stroke Patients'\n",
    "\n",
    "side_by_side_barplot(data_1, data_2, title_1, title_2, labels, feature, y, palette);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c1adb7",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * The percentage of patients with hypertension who also suffered a stroke is more than twice that of patients who did not.  \n",
    "> * Hypertension may be one of the indicators for a doctor to consider as a possible risk factor when it comes to identifying the likelihood of stroke. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad8632",
   "metadata": {},
   "source": [
    "## **Heart Disease**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Heart Disease'\n",
    "target = 'Stroke'\n",
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "wi_stroke_heart = create_distributions(data, feature, target, value = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c74f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stroke_heart = create_distributions(data, feature, target, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1]\n",
    "palette = [color_5, color_6]\n",
    "y = 'Count'\n",
    "\n",
    "data_1 = wi_stroke_heart\n",
    "data_2 = no_stroke_heart \n",
    "\n",
    "data_1 ['Heart Disease'] = data_1['Heart Disease'].replace({0: 'No', 1: 'Yes'})\n",
    "data_2 ['Heart Disease'] = data_2['Heart Disease'].replace({0: 'No', 1: 'Yes'})\n",
    "title_1 = 'Heart Disease Among Stroke Patients'\n",
    "title_2 = 'Heart Disease Among Non-Stroke Patients'\n",
    "\n",
    "side_by_side_barplot(data_1, data_2, title_1, title_2, labels, feature, y, palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8995973b",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * The percentage of patients with heart disease who also suffered a stroke is more than three times of this number for patients who did not.  \n",
    "> * Looking at this data, a doctor may consider heart disease as a possible risk factor when it comes to identifying the likelihood of stroke. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9002a90",
   "metadata": {},
   "source": [
    "## **Marital Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Ever Married'\n",
    "target = 'Stroke'\n",
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92988936",
   "metadata": {},
   "outputs": [],
   "source": [
    "wi_stroke_marriage = create_distributions(data, feature, target, value = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stroke_marriage = create_distributions(data, feature, target, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e85d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['No', 'Yes']\n",
    "palette = [color_7, color_8]\n",
    "y = 'Count'\n",
    "\n",
    "data_1 = wi_stroke_marriage\n",
    "data_2 = no_stroke_marriage\n",
    "title_1 = 'Marital Status Among Stroke Patients'\n",
    "title_2 = 'Marital Status Among Non-Stroke Patients'\n",
    "\n",
    "side_by_side_barplot(data_1, data_2, title_1, title_2, labels, feature, y, palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1cb7dc",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * It is an accepted idea that our psychological and social states can affect our biology and our susecptibility to illness.   \n",
    "> * Why is there nearly 3 times as many non-married people among patients who did not suffer a stroke? \n",
    "> * It is hard to say, but it gives us some reasons to look at the marital status of patients and the quality of such a relationship when it comes to identifying risk factors for stroke."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45cca49",
   "metadata": {},
   "source": [
    "## **Work Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745cf6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Work'\n",
    "target = 'Stroke'\n",
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "wi_stroke_work = create_distributions(data, feature, target, value = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19414ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stroke_work = create_distributions(data, feature, target, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Private', 'Self-employed', 'Govt_job', 'children', 'Never_worked']\n",
    "palette = [color_1, color_2, color_3, color_9, color_10]\n",
    "y = 'Count'\n",
    "\n",
    "data_1 = wi_stroke_work\n",
    "data_2 = no_stroke_work\n",
    "title_1 = 'Work Status Among Stroke Patients'\n",
    "title_2 = 'Work Status Among Non-Stroke Patients'\n",
    "\n",
    "side_by_side_barplot(data_1, data_2, title_1, title_2, labels, feature, y, palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad1345",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * The only significant difference here is that a big percentage of those who did not suffer a stroke are those too young to work. \n",
    "> * This will be significant later in the analysis. Perhaps we can eliminate the group below a certain age since they are not likely to have a stroke. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84335b93",
   "metadata": {},
   "source": [
    "## **Residence Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Residence'\n",
    "target = 'Stroke'\n",
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wi_stroke_residence = create_distributions(data, feature, target, value = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb52dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stroke_residence = create_distributions(data, feature, target, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Urban', 'Rural']\n",
    "palette = [color_9, color_10]\n",
    "y = 'Count'\n",
    "\n",
    "data_1 = wi_stroke_residence\n",
    "data_2 = no_stroke_residence\n",
    "title_1 = 'Residence Type Among Stroke Patients'\n",
    "title_2 = 'Residence Type  Among Non-Stroke Patients'\n",
    "\n",
    "side_by_side_barplot(data_1, data_2, title_1, title_2, labels, feature, y, palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428faa71",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * It seems that the place of residence (Urban or Rural) is not a significant factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ed9d7",
   "metadata": {},
   "source": [
    "## **Smoking Habits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Smoking'\n",
    "target = 'Stroke'\n",
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wi_stroke_smoking = create_distributions(data, feature, target, value = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751483a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stroke_smoking = create_distributions(data, feature, target, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42979318",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['formerly smoked', 'never smoked', 'smokes', 'Unknown']   \n",
    "palette = [color_8, color_9, color_10, color_11]\n",
    "y = 'Count'\n",
    "data_1 = wi_stroke_smoking\n",
    "data_2 = no_stroke_smoking\n",
    "title_1 = 'Smoking Stroke Patients'\n",
    "title_2 = 'Smoking Non-Stroke Patients'\n",
    "\n",
    "side_by_side_barplot(data_1, data_2, title_1, title_2, labels, feature, y, palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79021b42",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * These figures seem interesting. \n",
    "> * Although a higher percentage of those who formerly smoked are in the stroke category, the percentage of current smokers are about the same in both groups. \n",
    "> * I did not expect that. I was sure that smoking will be a significant risk factor. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067f7f0",
   "metadata": {},
   "source": [
    "## **Glucose Bins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'AVG Glucose'\n",
    "target = 'Stroke'\n",
    "new_feature = 'Glucose Bins'\n",
    "\n",
    "bins = [50, 100, 150, 200, 250, 300]\n",
    "labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8262bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "data = create_bins(df, feature, new_feature, bins, labels)\n",
    "data[new_feature] = data[new_feature].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b085f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data[target] == 1].copy()\n",
    "wi_stroke_glucose = count_bins(df, new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a742a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data[target] == 0].copy()\n",
    "no_stroke_glucose = count_bins(df, new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [color_9, color_10, color_11, color_13, color_14]\n",
    "y = 'Count'\n",
    "\n",
    "data_1 = wi_stroke_glucose\n",
    "data_2 = no_stroke_glucose\n",
    "title_1 = 'Glucose Levels Among Stroke Patients'\n",
    "title_2 = 'Glucose Levels Among Non-Stroke Patients'\n",
    "\n",
    "side_by_side_barplot(data_1, data_2, title_1, title_2, labels, new_feature, y, palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7477eafc",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * It seems that average glucose could be another risk factor contributing to stroke. \n",
    "> * 101 - 150: In this range, the average glucose levels of stroke and non-stroke patients do not seem to be very different. In fact, there is a slightly higher perectage of non-stroke patients at this glucose level.\n",
    "> * 151 - 200: More than twice the percentage of stroke patients have this average glucose level.\n",
    "> * 201 - 250: The percentage of stroke patients with this range of average glucose is nearly 3 times than those who did not suffer a stroke.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee017bb",
   "metadata": {},
   "source": [
    "# **BMI Bins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'BMI'\n",
    "new_feature = 'BMI Bins'\n",
    "bins = [10, 20, 30, 40, 50, 70]\n",
    "labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550106e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "data = create_bins(df, feature, new_feature, bins, labels)\n",
    "data[new_feature] = data[new_feature].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data[target] == 1]\n",
    "wi_stroke_BMI = count_bins(df, new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40690298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data[target] == 0]\n",
    "no_stroke_BMI = count_bins(df, new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c099f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [color_1, color_2, color_3, color_4, color_5,color_9, color_10, color_11, color_13, color_14]\n",
    "y = 'Count'\n",
    "\n",
    "data_1 = wi_stroke_BMI\n",
    "data_2 = no_stroke_BMI\n",
    "title_1 = 'BMI Levels Among Stroke Patients'\n",
    "title_2 = 'BMI Levels Among Non-Stroke Patients'\n",
    "\n",
    "side_by_side_barplot(data_1, data_2, title_1, title_2, labels, new_feature, y, palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71901be",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * Except at the lowest BMI range of 11 - 20, stroke and non-stroke patients seem to be nearly identical in their BMI scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95cb8a2",
   "metadata": {},
   "source": [
    "## **Age Bins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38804080",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Age'\n",
    "new_feature = 'Age Bins'\n",
    "bins = [0, 30, 50, 70, 80, 90]\n",
    "labels = ['0-30', '30-50', '50-70', '70-80', '80-90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "data = create_bins(df, feature, new_feature, bins, labels)\n",
    "data[new_feature] = data[new_feature].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6772987",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data[target] == 1]\n",
    "wi_stroke_age = count_bins(df, new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963dfd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data[target] == 0]\n",
    "no_stroke_age = count_bins(df, new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ded90",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [color_1, color_2, color_3, color_4, color_5,color_9, color_10, color_11, color_13, color_14]\n",
    "y = 'Count'\n",
    "\n",
    "data_1 = wi_stroke_age\n",
    "data_2 = no_stroke_age\n",
    "title_1 = 'Age of Stroke Patients'\n",
    "title_2 = 'Age of Non-Stroke Patients'\n",
    "\n",
    "side_by_side_barplot(data_1, data_2, title_1, title_2, labels, new_feature, y, palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5be447",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * It is obvious that a higher percentage of younger people are in the non-stroke group. \n",
    "> * In the 60 - 70 range, the percentage of stroke sufferers is more than three times than that patients who did not suffer a stroke. \n",
    "> * This clearly shows the role of age in this affliction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c0f66",
   "metadata": {},
   "source": [
    "# **Hypothesis Tests**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d076f5",
   "metadata": {},
   "source": [
    "## **Hypothesis Test: Smoking Habits and Stroke** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dbbfdf",
   "metadata": {},
   "source": [
    "### **Two-Proportion Z-Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419f8fc7",
   "metadata": {},
   "source": [
    "The Two-Proportion Z-Test is used to determine whether there is a significant difference between the proportions of two independent groups. The two groups must be independent of each other. he test assumes that the sample size in each group is large enough to approximate the a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e7c27",
   "metadata": {},
   "source": [
    "**Null**: There is no significant difference between the proporation of smokers who suffered a stroke and non-smokers.<BR>\n",
    "**Alternative**: A higher proportion of smokers suffered a stroke compared to non-smokers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e79c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Smoking'\n",
    "target = 'Stroke'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smokers = data.loc[data[feature] == 'smokes']\n",
    "count_smokers = smokers.shape[0]\n",
    "count_smoker_stroke = (smokers[target] == 1).sum()\n",
    "prop_smoker_stroke = count_smoker_stroke / count_smokers\n",
    "print(\n",
    "    f\"Proportion of smokers who have suffered a stroke {prop_smoker_stroke:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d509f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsmokers = data.loc[data[feature] == 'never smoked']\n",
    "count_nonsmokers = nonsmokers.shape[0]\n",
    "count_nonsmoker_stroke = (nonsmokers[target] == 1).sum()\n",
    "prop_nonsmoker_stroke = count_nonsmoker_stroke / count_nonsmokers\n",
    "print(\n",
    "    f\"Proportion of nonsmokers who have suffered a stroke {prop_nonsmoker_stroke:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.array([count_smoker_stroke, count_nonsmoker_stroke])\n",
    "denominator = np.array([count_smokers, count_nonsmokers])\n",
    "\n",
    "stat, pval = proportions_ztest(numerator, denominator, alternative=\"two-sided\")\n",
    "\n",
    "print(f\"The p-value is: {pval:.2f}\")\n",
    "\n",
    "if pval< 0.05:\n",
    "    print(\"Null hypothesis is rejected.\")\n",
    "else:\n",
    "    print(\"Failed to reject the null hypothesis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19c4ef5",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * This high p-value suggests that there is no significant evidence to reject the null hypothesis. In other words, any observed effect or difference is likely due to random chance rather than a true effect.\n",
    "> * The p-value of 0.54 is above the significance level threshold of 0.05 in the Standards section of this project.\n",
    "> * Based on this p-values, the null hypothesis is not rejected. \n",
    "> * This fits with our observations earlier when looking at percentage of smokers and non-smokers among patients who suffered a stroke and those who did not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee7e2c",
   "metadata": {},
   "source": [
    "## **Hypothesis Test: Mean Glucose Level and Stroke**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1edea4",
   "metadata": {},
   "source": [
    "### **Two-Sample T-Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddb3750",
   "metadata": {},
   "source": [
    "The two-sample t-test, is used to determine if there is a significant difference between the means of two independent groups. The groups being compared must be independent, the data in both groups must be normally distributed and the variances of the two groups must be equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c0d9c",
   "metadata": {},
   "source": [
    "**Null**: There is no significant difference between the mean AVG Glucose of patients who suffered a stroke and patients who did not.<BR>\n",
    "**Alternative**: The mean AVG Glucose of patients who suffered a stroke is significantly different than the mean AVG Glucose of patients who did not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b63676",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'AVG Glucose'\n",
    "target = 'Stroke'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45decf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stroke_glucose = data[data[target] == 0][feature]\n",
    "wi_stroke_glucose = data[data[target] == 1][feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ebddd",
   "metadata": {},
   "source": [
    "### **Numpy Variance Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ebb295",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_non_stroke_glucose = np.var(no_stroke_glucose)\n",
    "var_stroke_glucose = np.var(wi_stroke_glucose)\n",
    "\n",
    "if var_non_stroke_glucose == var_stroke_glucose:\n",
    "    variance = True\n",
    "else:\n",
    "    variance = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ab71a",
   "metadata": {},
   "source": [
    "### **Two-Sample T-Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f84568",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = two_sample_t_test(no_stroke_glucose,wi_stroke_glucose, variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266817f8",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * This low p-value suggests that there may be significant evidence to reject the null hypothesis. In other words, any observed effect or difference is not likely due to random chance alone and may a true effect.\n",
    "> * This suggests that average glucose level could a significant risk factor for stroke and it goes with our earlier observation of average glucose levels in patients who suffered a stroke and those who did not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d695bad",
   "metadata": {},
   "source": [
    "# **Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991f414",
   "metadata": {},
   "source": [
    "In this section, I create new features from existing ones in hopes of improving model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f2716",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_engineered = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278d067",
   "metadata": {},
   "source": [
    "### **Missing Indicator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ami = AddMissingIndicator()\n",
    "ami.fit(data_engineered)\n",
    "data_engineered = ami.transform(data_engineered)\n",
    "data_engineered.rename(columns={'BMI_na': 'BMI_NAN'}, inplace=True)\n",
    "data_engineered.rename(columns={'BMI Bins_na': 'BMI Bins_NAN'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9deec",
   "metadata": {},
   "source": [
    "### **Random Sample Imputer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7361aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi = RandomSampleImputer()\n",
    "rsi.fit(data_engineered)\n",
    "data_engineered = rsi.transform(data_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55f66c",
   "metadata": {},
   "source": [
    "### **Sum Glucose / Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ba8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MathFeatures(variables = [\"AVG Glucose\",'Age'], func = \"sum\")\n",
    "mf.fit(data_engineered)\n",
    "data_engineered= mf.transform(data_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e22dc22",
   "metadata": {},
   "source": [
    "### **Product Glucose / Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MathFeatures(variables = [\"AVG Glucose\",'Age'], func = \"prod\")\n",
    "mf.fit(data_engineered)\n",
    "data_engineered= mf.transform(data_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a752f4",
   "metadata": {},
   "source": [
    "### **Mean Glucose / Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17030c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MathFeatures(variables = [\"AVG Glucose\",'Age'], func = \"mean\")\n",
    "mf.fit(data_engineered)\n",
    "data_engineered= mf.transform(data_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca4a4b",
   "metadata": {},
   "source": [
    "### **Hypertenstion OR Heart Disease**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb630d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_engineered['Hypertension or Heart_Disease'] = data_engineered['Hypertension'] | data_engineered['Heart Disease']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94de6c",
   "metadata": {},
   "source": [
    "### **Hypertenstion AND Heart Disease**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_engineered['Hypertension and Heart_Disease'] = data_engineered['Hypertension'] & data_engineered['Heart Disease']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae9d145",
   "metadata": {},
   "source": [
    "### **Label Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b88d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "obj = data_engineered.dtypes == \"object\"\n",
    "\n",
    "for col in list(obj[obj].index):\n",
    "    data_engineered[col] = label_encoder.fit_transform(data_engineered[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a44e5c",
   "metadata": {},
   "source": [
    "### **Correlation between each Feature and the Target Feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data_engineered.corr(numeric_only=True)\n",
    "corr_matrix['Stroke'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a95024",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Correlation of Features\"\n",
    "create_heatmap(data_engineered, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52afe4a",
   "metadata": {},
   "source": [
    "### **Drop Collinear Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0610e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcf = DropCorrelatedFeatures(threshold=0.7)\n",
    "data_engineered = dcf.fit_transform(data_engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626727ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data_engineered.corr(numeric_only=True)\n",
    "corr_matrix['Stroke'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Correlation of Features\"\n",
    "create_heatmap(data_engineered, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291fd8d4",
   "metadata": {},
   "source": [
    "### **Mutual Information Plot**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f685e",
   "metadata": {},
   "source": [
    "This plot shows the predicitve power of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159423ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_engineered.drop('Stroke', axis=1)\n",
    "target = data_engineered['Stroke']\n",
    "\n",
    "mi_scores = mutual_info_classif(features, target, random_state=random_state)\n",
    "create_plot_mi_scores(features, mi_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6573065",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * In this section, I dealth with missing values in the BMI and BMI related columns.\n",
    "> * I created 5 additional features based on the existing features.\n",
    "> * Using Feature Engine library, I dropped collinear features.\n",
    "> * The mutual information column clearly identifies age as the major predictor of stroke."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61269d7",
   "metadata": {},
   "source": [
    "# **Machine Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0faa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb11615",
   "metadata": {},
   "source": [
    "## **Eliminate White Space in Column Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_engineered.columns = [col.replace(' ', '_') for col in data_engineered.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764525d7",
   "metadata": {},
   "source": [
    "## **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9362d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_engineered.drop('Stroke', axis=1)\n",
    "y = data_engineered['Stroke']\n",
    "\n",
    "X, y = shuffle(X, y, random_state=random_state)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)\n",
    "\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9966fd4",
   "metadata": {},
   "source": [
    "## **K-Fold Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['Age', 'AVG_Glucose', 'BMI']\n",
    "columns_to_impute = ['BMI']\n",
    "X[columns_to_impute] = X[columns_to_impute].fillna(X[columns_to_impute].median())\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', RobustScaler(), columns_to_scale)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "svc_model = SVC(class_weight='balanced')\n",
    "svc_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svc', svc_model)\n",
    "])\n",
    "\n",
    "\n",
    "lg_model = LogisticRegression(class_weight='balanced', max_iter=5000)\n",
    "lg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lg', lg_model)\n",
    "])\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', xgb_model)\n",
    "])\n",
    "\n",
    "\n",
    "lgbm_model = LGBMClassifier(class_weight='balanced', verbose=0)\n",
    "lgbm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lgbm', lgbm_model)\n",
    "])\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=random_state)\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf', rf_model)\n",
    "])\n",
    "\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=random_state)\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gb', gb_model)\n",
    "])\n",
    "\n",
    "\n",
    "pipelines = {\n",
    "    \"SVC\": svc_pipeline,\n",
    "    \"Logistic Regression\": lg_pipeline,\n",
    "    \"XGBoost\": xgb_pipeline,\n",
    "    \"LightGBM\": lgbm_pipeline,\n",
    "    \"Random Forest\": rf_pipeline,\n",
    "    \"Gradient Boosting\": gb_pipeline\n",
    "}\n",
    "\n",
    "\n",
    "scorer = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    scores = cross_val_score(pipeline, X, y, cv=10, scoring=scorer)\n",
    "    print(f\"{name}: Mean Recall:  {scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a9b67",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * In this section, I used cross valildation to test 6 different models on the engineered dataset.\n",
    "> * Logistic Regression surpassed the other models with an accuracy score of 79%, also surpasoing my standard accuracy score of 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a22c06",
   "metadata": {},
   "source": [
    "## **Patients Over Age 50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b079f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overfifty = data_engineered[data_engineered['Age'] > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f84bc7",
   "metadata": {},
   "source": [
    "### **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82471ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_overfifty.drop('Stroke', axis=1)\n",
    "y = data_overfifty['Stroke']\n",
    "\n",
    "X, y = shuffle(X, y, random_state=random_state)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)\n",
    "\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165a121",
   "metadata": {},
   "source": [
    "### **K-Fold Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811125f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['Age', 'AVG_Glucose', 'BMI']\n",
    "columns_to_impute = ['BMI']\n",
    "X[columns_to_impute] = X[columns_to_impute].fillna(X[columns_to_impute].median())\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', RobustScaler(), columns_to_scale)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "svc_model = SVC(class_weight='balanced')\n",
    "svc_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svc', svc_model)\n",
    "])\n",
    "\n",
    "\n",
    "lg_model = LogisticRegression(class_weight='balanced', max_iter=5000)\n",
    "lg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lg', lg_model)\n",
    "])\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', xgb_model)\n",
    "])\n",
    "\n",
    "\n",
    "lgbm_model = LGBMClassifier(class_weight='balanced', verbose=0)\n",
    "lgbm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lgbm', lgbm_model)\n",
    "])\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=random_state)\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf', rf_model)\n",
    "])\n",
    "\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=random_state)\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gb', gb_model)\n",
    "])\n",
    "\n",
    "\n",
    "pipelines = {\n",
    "    \"SVC\": svc_pipeline,\n",
    "    \"Logistic Regression\": lg_pipeline,\n",
    "    \"XGBoost\": xgb_pipeline,\n",
    "    \"LightGBM\": lgbm_pipeline,\n",
    "    \"Random Forest\": rf_pipeline,\n",
    "    \"Gradient Boosting\": gb_pipeline\n",
    "}\n",
    "\n",
    "\n",
    "scorer = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    scores = cross_val_score(pipeline, X, y, cv=10, scoring=scorer)\n",
    "    print(f\"{name}: Mean Recall:  {scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a5ed5e",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * In this section, I used cross valildation to test 6 different models on the engineered dataset on a dataset limited to patient over 50, since the data showed that these patients are more likely to suffer a stroke.\n",
    "> * None of the models surpassed the accuracy score of 75%, also surpasoing my standard accuracy score of 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9dd447",
   "metadata": {},
   "source": [
    "## **Age, Hypertension, Heart Disease, Average Glucose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472756e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['Age', 'Hypertension', 'Heart_Disease','AVG_Glucose', 'Stroke']\n",
    "data_mainfeatures = data_engineered[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c11b968",
   "metadata": {},
   "source": [
    "### **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dba354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_mainfeatures.drop('Stroke', axis=1)\n",
    "y = data_mainfeatures['Stroke']\n",
    "\n",
    "X, y = shuffle(X, y, random_state=random_state)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)\n",
    "\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d320a",
   "metadata": {},
   "source": [
    "### **K-Fold Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['Age', 'AVG_Glucose']\n",
    "# X[columns_to_impute] = X[columns_to_impute].fillna(X[columns_to_impute].median())\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', RobustScaler(), columns_to_scale)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "svc_model = SVC(class_weight='balanced')\n",
    "svc_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svc', svc_model)\n",
    "])\n",
    "\n",
    "\n",
    "lg_model = LogisticRegression(class_weight='balanced', max_iter=5000)\n",
    "lg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lg', lg_model)\n",
    "])\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', xgb_model)\n",
    "])\n",
    "\n",
    "\n",
    "lgbm_model = LGBMClassifier(class_weight='balanced', verbose=0)\n",
    "lgbm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lgbm', lgbm_model)\n",
    "])\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=random_state)\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf', rf_model)\n",
    "])\n",
    "\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=random_state)\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gb', gb_model)\n",
    "])\n",
    "\n",
    "\n",
    "pipelines = {\n",
    "    \"SVC\": svc_pipeline,\n",
    "    \"Logistic Regression\": lg_pipeline,\n",
    "    \"XGBoost\": xgb_pipeline,\n",
    "    \"LightGBM\": lgbm_pipeline,\n",
    "    \"Random Forest\": rf_pipeline,\n",
    "    \"Gradient Boosting\": gb_pipeline\n",
    "}\n",
    "\n",
    "\n",
    "scorer = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    scores = cross_val_score(pipeline, X, y, cv=10, scoring=scorer)\n",
    "    print(f\"{name}: Mean Recall:  {scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea8073",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * In this section, I used cross valildation to test 6 different models on the engineered dataset on a limited data set of 4 features only, the 4 features that showed the most predictive power of all the other ones.\n",
    "> * Both Logistic Regression and SVC surpassed the other models with an accuracy score of 79% and 82% respectively, also surpasoing my standard accuracy score of 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d4d4d",
   "metadata": {},
   "source": [
    "## **Tuned SVC Hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b15309",
   "metadata": {},
   "source": [
    "### **SVC Pipeline Optimized**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a6784",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['Age', 'AVG_Glucose']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', RobustScaler(), columns_to_scale)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "svc_model_optimized = SVC(kernel='linear', gamma='auto', C=0.1, class_weight='balanced')\n",
    "svc_pipeline_optimized = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svc', svc_model)\n",
    "])\n",
    "\n",
    "\n",
    "pipelines = {\n",
    "    \"SVC\": svc_pipeline_optimized,\n",
    "}\n",
    "\n",
    "scorer = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    scores = cross_val_score(pipeline, X, y, cv=10, scoring=scorer)\n",
    "    print(f\"{name}: Mean Recall:  {scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipeline_optimized.fit(X, y)\n",
    "\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "cv_results = cross_validate(svc_pipeline_optimized, X, y, cv=5, scoring={'recall': recall_scorer})\n",
    "\n",
    "print(\"Recall scores for each fold:\", cv_results['test_recall'])\n",
    "print(\"Mean recall score:\", cv_results['test_recall'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc12db9",
   "metadata": {},
   "source": [
    "### **Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa704ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_pipeline_optimized.predict(X_test)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5544099",
   "metadata": {},
   "source": [
    "### **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd488c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = ConfusionMatrixDisplay.from_estimator (svc_pipeline_optimized, X_test, y_test, cmap=plt.cm.Reds)\n",
    "\n",
    "conf_matrix.ax_.set_xticks([0, 1])\n",
    "conf_matrix.ax_.set_xticklabels([\"No\", \"Yes\"])\n",
    "conf_matrix.ax_.set_yticks([0, 1])\n",
    "conf_matrix.ax_.set_yticklabels([\"No\", \"Yes\"])\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9453c",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * In this section, I tried to optimize my SVC model using hyperparameter tuning. The results were similar to those I received without tuning, 82% recall.\n",
    "> * SVC showed the best performance of all the other models, so I used it as my final model for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e21766",
   "metadata": {},
   "source": [
    "# **Create a Pickle File for Streamlit Deployment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svc_pipeline_optimized.pkl', 'wb') as file:\n",
    "    pickle.dump(svc_pipeline_optimized, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1224f5",
   "metadata": {},
   "source": [
    "### **Section Summary**\n",
    "> * Using this final model, I created a Streamlit application for final deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a69d7",
   "metadata": {},
   "source": [
    "# **Conclusions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ac04d",
   "metadata": {},
   "source": [
    "Here is a summary of the conclusions that may be drawn from this report. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325cc872",
   "metadata": {},
   "source": [
    ">* **The Analysis of the Data:** I reviewed over 5,000 datapoint related to patients with stroke. <br> \n",
    ">* **The Goal of the Project:** The goal of this project was to find a model that could predict if a patient is likely to have a stroke with a recall score of 0.75 or higher.<br>\n",
    ">* **Models:** I utilized numerous models and numerous ways to hyperparameter tuning.  I chose two simple models, Logistic Regressin and Support Vector Machines. I chose two boosting classifiers, LGBM and XGB and two ensemble models: Random Forest Classifier and Gradient Boosting Classifier.<br>\n",
    ">* **Encoding:** For categorical data, I tried both Label Encoding and One-Hot Encoding. I did not see significant differences. I chose Label Encoding since the resulting table was more readable.  <br>\n",
    ">* **Imputing Missing Data:** For imputing missing data, I tried mean, median, zero and random imputers. I saw no signinficant difference between them in the predictions of my models. I chose Randmo Imputer, since it I thought with such little information about the participants, it makes no sense to make any judgments about their features.  <br>\n",
    ">* **Feature Engineering and Hyperparameter Testing:** I tried feature engineering and hyperparameter testing with techniques such as Backward Elimination, SHAP and OPTUNA. Some, I included in this report and some I didn't for sake of brevity. None of the measures I utilized improved resutls significanlty.<br> \n",
    ">* **Support Vector Classification:** For a simple model and using only default hyperparameters, SVC was able to get better or similar results than any other model, including the more complex ones.<br>  \n",
    ">* **Boosting Models:** Of the boosting models that I utilized, none of them performed better than SVC.\n",
    ">* **Ensemble Models:** Of the ensemble models that I utilized, none of them performed better than SVC.\n",
    ">* **Recommendation:** I am not able to make any medical recommendations based on this data. However, some obvious elements that I was sure would contribute to the risk of stroke such as smoking or BMI, turned out to be a very poor predictors. <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c7f3d5",
   "metadata": {},
   "source": [
    "# **Suggestions for Improvement**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885cf09",
   "metadata": {},
   "source": [
    "This report has certain weaknesses. In this section, I outlined those weaknesses and indicated some avenues for improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c766e",
   "metadata": {},
   "source": [
    ">* **Domain Knowledge:** It is best if the data scientist has adequate domain knowledge on the topic of the analysis. I do not have any expertise in the medical field. There may be parts of the data that I have overlooked that may have been important and I may have given importance to parts that may have had little significance. <br>\n",
    ">* **More Detailed Data:** The data provide only general information on patients. This information is not adequate to predict a disease as complex as stroke. Information such as family history, genetic markers, blood trace element markers and more are missing in this data. More detailed information could have helped make better predictions. <br>  \n",
    ">* **Balance:** The data is heavely imbalanced. Of the more than 5,000 datapoints, only about 300 are related to stroke patients. This, in addition to inadequcy of the data as mentioned above adds to the complexity predictions.  <br>  \n",
    ">* **Visualizations:** If I had more time, I would improve on the bar graphs to emphasize certain data by using specific colors.  <br>  \n",
    ">* **Functions:** I modularized most of the code in this notebook but not all due to limitation of time.  <br>  \n",
    ">* **Statistics:** Continue to improve my statistical knowledge to create better analyses.<br>\n",
    ">* **Pandas:** Continue to learn to utilize more optimized Pandas techniques and algorithms.<br>\n",
    ">* **Seaborn and Matplotlib:** Continue to improve my knowledge of Seaborn and Matplotlib for creating visualizations. <br>\n",
    ">* **Python Code:** Continue to write better and more efficient Python code. <br>\n",
    ">* **Clean Code:** Continue to adhere to the principles of writing clean code. <br>\n",
    ">* **Readability and Efficiency:** Continue to improve my skills to find the delicate balance between readability and efficiency in coding.<br>\n",
    ">* **Functions File:** For my next project, I will create a file with my functions, separate from the notebook file, to keep the notebook as a more reasonable length.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c38aa4",
   "metadata": {},
   "source": [
    "# **Appendix**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a48503",
   "metadata": {},
   "source": [
    "## **Model Development Techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3800a1aa",
   "metadata": {},
   "source": [
    ">* **Batch Inference:** In batch inference, predictions are made on a large set of data at scheduled intervals.\n",
    ">* **Real-Time Inference:** In online inference, predictions are made in real-time as requests arrive.\n",
    ">* **Hybrid Interface:** Combines batch and online inference to leverage the benefits of both batch and real-time Interface.\n",
    ">* **Shadow Mode Deployment:** A new model runs in parallel with the existing model but does not affect production outcomes. The results are logged for comparison.\n",
    ">* **Canary Deployment:** A small subset of users is exposed to the new model, while the majority continues to use the old model. Based on performance, the new model is gradually rolled out to all users.\n",
    ">* **A/B Testing:** Two or more models are deployed simultaneously to different user segments to evaluate which model performs better.\n",
    ">* **Blue-Green Deployment:** Two identical environments (blue and green) are maintained. The new model is deployed to the blue environment while the green remains live. After validation, traffic is switched to the blue environment.\n",
    ">* **Multi-Armed Bandit:** An extension of A/B testing that dynamically allocates traffic to the best-performing model based on ongoing results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ff6a1",
   "metadata": {},
   "source": [
    "## **Boosting Models Used in this Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde596e",
   "metadata": {},
   "source": [
    ">* **XGBoost (Extreme Gradient Boosting):** XGBoost (Extreme Gradient Boosting) uses the gradient boosting framework, where weak learners are sequentially added to the model, each one correcting the errors of its predecessor. XGBoost includes regularization terms (L1 and L2) to prevent overfitting and improve model generalization. XGBoost can handle missing data internally.<br>\n",
    ">* **LightGBM (Light Gradient Boosting Machine):** LightGBM (Light Gradient Boosting Machine) is a gradient boosting framework developed by Microsoft, ightGBM can directly handle categorical features without needing to pre-process them into numerical forms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
