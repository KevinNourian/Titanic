{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25aaf1b5",
   "metadata": {},
   "source": [
    "# <center> **Titanic**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c8da2",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e35264",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianNB\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Documents\\AI\\Titanic\\new_env\\lib\\site-packages\\catboost\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     FeaturesData, EFstrType, EShapCalcType, EFeaturesSelectionAlgorithm, EFeaturesSelectionGrouping,\n\u001b[0;32m      3\u001b[0m     Pool, CatBoost, CatBoostClassifier, CatBoostRegressor, CatBoostRanker, CatBoostError, cv, sample_gaussian_process, train,\n\u001b[0;32m      4\u001b[0m     sum_models, _have_equal_features, to_regressor, to_classifier, to_ranker, MultiRegressionCustomMetric,\n\u001b[0;32m      5\u001b[0m     MultiRegressionCustomObjective, MultiTargetCustomMetric, MultiTargetCustomObjective\n\u001b[0;32m      6\u001b[0m )  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VERSION \u001b[38;5;28;01mas\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeaturesData\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFstrType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEShapCalcType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionAlgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionGrouping\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPool\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRegressor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRanker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatboostError\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomMetric\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomObjective\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Documents\\AI\\Titanic\\new_env\\lib\\site-packages\\catboost\\core.py:45\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_plot_file, try_plot_offline, OfflineMetricVisualizer\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BuiltinMetric\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Documents\\AI\\Titanic\\new_env\\lib\\site-packages\\catboost\\plot_helpers.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[0;32m      6\u001b[0m fspath \u001b[38;5;241m=\u001b[39m _catboost\u001b[38;5;241m.\u001b[39mfspath\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_plot_offline\u001b[39m(figs):\n",
      "File \u001b[1;32m_catboost.pyx:1\u001b[0m, in \u001b[0;36minit _catboost\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169bb5d",
   "metadata": {},
   "source": [
    "# **Data Overview and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e358ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    r\"C:\\Users\\Dell\\Documents\\AI\\Titanic\\Data\\data.csv\",\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "train = pd.read_csv(\n",
    "    r\"C:\\Users\\Dell\\Documents\\AI\\Titanic\\Data\\Data\\train.csv\",\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "test = pd.read_csv(\n",
    "    r\"C:\\Users\\Dell\\Documents\\AI\\Titanic\\Data\\Data\\test.csv\",\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "\n",
    "random_state = 101\n",
    "target = 'Transported'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c97564",
   "metadata": {},
   "source": [
    "# **Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3663d",
   "metadata": {},
   "source": [
    "## **Split Data Back to Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a099298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=data[data['PassengerId'].isin(train['PassengerId'].values)].copy()\n",
    "test=data[data['PassengerId'].isin(test['PassengerId'].values)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d267b4e",
   "metadata": {},
   "source": [
    "# **Drop Unneeded Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8f18a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['PassengerId', 'Group', 'CabinNumber'], axis=1, inplace=True)\n",
    "test.drop(['PassengerId', 'Group', 'CabinNumber'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28f9b8",
   "metadata": {},
   "source": [
    "# **Log Transform**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe888dfb",
   "metadata": {},
   "source": [
    "The logarithm transform is used to decrease skew in distributions, especially with large outliers. It can make it easier for algorithms to 'learn' the correct relationships. We will apply it to the expenditure features as these are heavily skewed by outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaa7d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_transform = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'TotalSpent']  # Replace with your actual column names\n",
    "\n",
    "for col in columns_to_transform:\n",
    "    train = functions.log_transform(train, col)\n",
    "    test = functions.log_transform(test, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e753e26",
   "metadata": {},
   "source": [
    "## **Column Separation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68029f11",
   "metadata": {},
   "source": [
    "### **Numerical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f60d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [cname for cname in train.columns if train[cname].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8494704",
   "metadata": {},
   "source": [
    "### **Categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56bc4455",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [cname for cname in train.columns if train[cname].dtype in [\"object\", \"bool\"]]\n",
    "categorical_cols.remove(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccdb9b",
   "metadata": {},
   "source": [
    "## **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3c1ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(target, axis=1)\n",
    "y = train[target]\n",
    "y = y.astype(bool)\n",
    "\n",
    "\n",
    "X, y = shuffle(X, y, random_state=random_state)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80391a5d",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7416d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.77 (0.67 minutes)\n",
      "KNN: 0.75 (0.20 minutes)\n",
      "Random Forest: 0.79 (2.12 minutes)\n",
      "XGBoost: 0.80 (0.78 minutes)\n",
      "LightGBM: 0.80 (0.14 minutes)\n",
      "Naive Bayes: 0.53 (0.17 minutes)\n"
     ]
    }
   ],
   "source": [
    "numerical_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "preprocessor  = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "\n",
    "lg_model = LogisticRegression(random_state=random_state, max_iter=5000)\n",
    "lg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lg', lg_model)\n",
    "])\n",
    "\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', knn_model)\n",
    "])  \n",
    "\n",
    "# svm_model = SVC(random_state=random_state, probability=True)\n",
    "# svm_pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('svm', svm_model)\n",
    "# ])\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=random_state)\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('random_forest', rf_model)\n",
    "])\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', xgb_model)\n",
    "])\n",
    "\n",
    "lgbm_model = LGBMClassifier(random_state=random_state, verbose=0)\n",
    "lgbm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lgbm', lgbm_model)\n",
    "])\n",
    "\n",
    "# catboost_model = CatBoostClassifier(random_state=random_state, verbose=0)\n",
    "# catboost_pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('catboost', catboost_model)\n",
    "# ])  \n",
    "\n",
    "naive_bayes_model = GaussianNB()\n",
    "naive_bayes_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('naive_bayes', naive_bayes_model)\n",
    "])\n",
    "\n",
    "\n",
    "pipelines = {\n",
    "    \"Logistic Regression\": lg_pipeline,\n",
    "    \"KNN\": knn_pipeline,\n",
    "    # \"SVM\": svm_pipeline,\n",
    "    \"Random Forest\": rf_pipeline,\n",
    "    \"XGBoost\": xgb_pipeline,\n",
    "    \"LightGBM\": lgbm_pipeline,\n",
    "    # \"CatBoost\": catboost_pipeline,\n",
    "    \"Naive Bayes\": naive_bayes_pipeline\n",
    "}\n",
    "\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    start_time = time.time()  \n",
    "    scores = cross_val_score(pipeline, X, y, cv=10)\n",
    "    end_time = time.time()  \n",
    "    elapsed_time = (end_time - start_time)/60  \n",
    "    \n",
    "    print(f\"{name}: {scores.mean():.2f} ({elapsed_time:.2f} minutes)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
